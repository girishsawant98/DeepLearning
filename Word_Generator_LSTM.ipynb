{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout  \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "#save the file\n",
    "with open('hamlet.txt', 'w') as file:\n",
    "    file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the dataset\n",
    "\n",
    "with open('hamlet.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "#Tokenize the text\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating input sequences \n",
    "\n",
    "inputsequences = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1, len(token_list)):\n",
    "    n_gram_sequence = token_list[:i+1]\n",
    "    inputsequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad Sequences \n",
    "\n",
    "max_sequence_len = max([len(x) for x in inputsequences])\n",
    "inputsequences = np.array(pad_sequences(inputsequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Predictors and label\n",
    "\n",
    "X, y = inputsequences[:,:-1], inputsequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)  #Converting y into categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1219418 (4.65 MB)\n",
      "Trainable params: 1219418 (4.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Training our LSTM Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation = \"softmax\"))\n",
    "\n",
    "#Compile the model\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 2.6060 - accuracy: 0.4272 - val_loss: 11.6241 - val_accuracy: 0.0527\n",
      "Epoch 2/50\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 2.5699 - accuracy: 0.4361 - val_loss: 11.6956 - val_accuracy: 0.0521\n",
      "Epoch 3/50\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 2.5370 - accuracy: 0.4371 - val_loss: 11.7501 - val_accuracy: 0.0538\n",
      "Epoch 4/50\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 2.5079 - accuracy: 0.4444 - val_loss: 11.8443 - val_accuracy: 0.0515\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model \n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=[X_test, y_test], verbose=1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:To be or not be\n",
      "Next word prediction:blame\n"
     ]
    }
   ],
   "source": [
    "#preditcion function \n",
    "\n",
    "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "    if len(token_list) >= max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]\n",
    "    \n",
    "    token_list = pad_sequences([token_list], maxlen= max_sequence_len-1, padding = 'pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None\n",
    " \n",
    "\n",
    "input_text = \"To be or not be\"\n",
    "print(f\"Input Text:{input_text}\")\n",
    "max_sequence_len = model.input_shape[1]+1\n",
    "next_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n",
    "print(f\"Next word prediction:{next_word}\")\n",
    "\n",
    "\n",
    "model.save(\"next_word_lstm.h5\")\n",
    "#Save tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tokenizer.pickle\", 'wb') as file:\n",
    "    pickle.dump(tokenizer, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
